import os
import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

NORM_MEAN = [0.485, 0.456, 0.406]
NORM_STD = [0.229, 0.224, 0.225]
IMG_SIZE = 224

def get_transforms(is_train=True):
    """
    TÃ¡ch biá»‡t quy trÃ¬nh Augmentation Ä‘á»ƒ dá»… quáº£n lÃ½ trong Thesis.
    """
    if is_train:
        return transforms.Compose([
            transforms.Resize([256, 256]),
            transforms.ColorJitter(brightness=0.2, contrast=0.2), # TÄƒng chá»‰nh Ä‘á»™ sÃ¡ng nháº¹
            transforms.RandomCrop(IMG_SIZE),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomVerticalFlip(p=0.5),
            transforms.ToTensor(),
            transforms.Normalize(NORM_MEAN, NORM_STD)
        ])
    else:
        return transforms.Compose([
            transforms.Resize([IMG_SIZE, IMG_SIZE]),
            transforms.ToTensor(),
            transforms.Normalize(NORM_MEAN, NORM_STD)
        ])

def load_data(root_path, phase='train', batch_size=32, num_workers=2):
    """
    HÃ m náº¡p dá»¯ liá»‡u tá»•ng quÃ¡t.
    Args:
        root_path: ÄÆ°á»ng dáº«n gá»‘c (vÃ­ dá»¥: /kaggle/input/dataset)
        phase: 'train' hoáº·c 'test' (tÆ°Æ¡ng á»©ng vá»›i tÃªn thÆ° má»¥c con)
    """
    data_dir = os.path.join(root_path, phase)
    is_train = (phase == 'train')
    
    transform = get_transforms(is_train=is_train)
    
    dataset = datasets.ImageFolder(root=data_dir, transform=transform)
    
    loader = DataLoader(
        dataset, 
        batch_size=batch_size, 
        shuffle=is_train, 
        num_workers=num_workers,
        drop_last=is_train
    )
    
    if not is_train:
        filenames = [os.path.basename(x[0]) for x in dataset.imgs]
        labels = dataset.targets
        return loader, filenames, labels
        
    return loader

if __name__ == '__main__':
    import argparse
    # 1. Thiáº¿t láº­p nháº­n tham sá»‘ tá»« Kaggle
    parser = argparse.ArgumentParser()
    parser.add_argument('--data_path', type=str, required=True, help='ÄÆ°á»ng dáº«n tá»›i dataset trÃªn Kaggle')
    parser.add_argument('--batch_size', type=int, default=8)
    args = parser.parse_args()

    print(f"ğŸš€ Báº¯t Ä‘áº§u kiá»ƒm tra táº¡i: {args.data_path}")

    try:
        # 2. Gá»i hÃ m load_data
        # ChÃºng ta thá»­ load táº­p train
        loader = load_data(args.data_path, phase='train', batch_size=args.batch_size)
        
        print(f"ğŸ“‚ ÄÃ£ tÃ¬m tháº¥y cÃ¡c lá»›p: {loader.dataset.classes}")
        print(f"ğŸ”¢ Tá»•ng sá»‘ áº£nh: {len(loader.dataset)}")

        # 3. HÃ€NH Äá»˜NG QUYáº¾T Äá»ŠNH: Láº¥y thá»­ 1 batch áº£nh thá»±c táº¿
        images, labels = next(iter(loader))

        # 4. Náº¿u in Ä‘Æ°á»£c dÃ²ng nÃ y, báº¡n Ä‘Ã£ THÃ€NH CÃ”NG 100%
        print("\n" + "="*30)
        print("âœ… Káº¾T QUáº¢: LOAD DATA THÃ€NH CÃ”NG!")
        print(f"ğŸ“¦ KÃ­ch thÆ°á»›c Tensor áº£nh: {images.shape}") # NÃªn lÃ  [8, 3, 224, 224]
        print(f"ğŸ·ï¸ NhÃ£n cÃ¡c áº£nh trong batch: {labels.tolist()}")
        print("="*30)

    except FileNotFoundError:
        print(f"âŒ Lá»–I: KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c 'train' táº¡i {args.data_path}")
    except Exception as e:
        print(f"âŒ Lá»–I Há»† THá»NG: {e}")
